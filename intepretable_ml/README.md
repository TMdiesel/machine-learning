# interpretable ml
- 教師ありモデルの解釈手法のまとめです。

## 手法まとめ
|手法|モデル|解釈|大域/局所|アルゴリズム|長所|短所|
|:----|:----|:----|:----|:----|:----|:----|
|一般化線形モデル|依存|要約|両方|特徴量重要度(t統計量) or 重み| | |
|tree系|依存|要約|大域|対象特徴量が使われる分岐で親のノードに比べてどれだけジニ不純度/分散を減少させているか| | |
|PDP|非依存|視覚|大域|それぞれのインスタンスの特徴量の値をvとしたときの、モデルの予測の平均|直感的に理解できる|特徴量の分布に含まれないものがある、独立性の仮定|
|ICE|非依存|視覚|局所|インスタンスごとに、xcを固定してxsの関数を得る|直感的に理解できる|特徴量の分布に含まれないものがある、独立性の仮定|
|ALE|非依存|視覚|大域|その特徴量が約vであるインスタンスに対して、小さな窓の中でモデルの予測がどう変化するか|特徴量の相関があっても機能する、PDPより計算が高速|区間数を決定する必要がある|
|PFI|非依存|要約|大域|対象特徴量を並び替えたあとのモデルの予測誤差の影響を計算|相互作用を考慮に入れる|正解データが必要、特徴量の相関を無視|
|global surrogate|非依存|要約|大域|機械学習モデルの予測結果を解釈可能なモデルで学習|直感的に理解できる|単純なモデルの解釈が全てのデータ点に対して等しく優れているとは言えない|
|LIME|非依存|要約|局所|局所的な摂動空間内のインスタンスを、解釈可能なモデルでサロゲート|直感的に理解できる|摂動の与え方が難しい、説明が不安定|
|Anchor|非依存|述部|局所|局所的な摂動空間内のAnchor(if-thenルール)の精度が高くなるようにする|LIMEより解釈しやすい、非線形の場合も機能|離散化が必要、ハイパラが多い|
|Kernel shap|非依存|要約|両方|全ての連合に対する平均周辺寄与の推定|任意のモデルに使用可能、予測と予測の平均の差分を特徴量間で公平に分配|計算時間が長い、特徴量の相関を無視|
|Tree shap|非依存|要約  |両方|Kernel shapの効率化|計算が高速、予測と予測の平均の差分を特徴量間で公平に分配|tree系のみ、特徴量の相関を無視|

## 参考
- [Interpretable Machine Learning](https://hacarus.github.io/interpretable-ml-book-ja/)

